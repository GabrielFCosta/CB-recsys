{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielFCosta/TCC-BSI-2023.1/blob/main/old/matc97_gabriel_teste_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g1zLg3Ipx77",
        "outputId": "9113299e-0e8b-40fc-b31c-ec3a91eb9837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWcc_InWq1HI",
        "outputId": "4bd44ea6-c58e-438f-919c-c48b25f21842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import string\n",
        "import math\n",
        "import nltk\n",
        "import random\n",
        "import pandas as pd\n",
        "import time as tm\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1C1u6qgrWtg"
      },
      "outputs": [],
      "source": [
        "# Função de tokenização e POS tagging recebe string \n",
        "# retorna lista de tuplas contendo palavras e respectivas classes gramaticais\n",
        "def postagtokenize(text):\n",
        "  return pos_tag(word_tokenize(text))\n",
        "\n",
        "# Retorna dataframe de palavras e frequências\n",
        "# recebe lista de dados (words) e nome da coluna (colname)\n",
        "def returndataset(words,colname):\n",
        "  # junta listas de palavras e rótulos num dataframe\n",
        "  dataset = pd.DataFrame(zip(words),columns =[colname])\n",
        "  # calcula frequências das palavras e adiciona nova coluna 'freq'\n",
        "  dataset['freq'] = dataset.groupby([colname])[colname].transform('count')\n",
        "  return dataclean(dataset)\n",
        " \n",
        "# Remove linhas duplicatas e atualiza index do dataframe\n",
        "def dataclean(dataset):\n",
        "  dataset.drop_duplicates(inplace = True)\n",
        "  dataset.reset_index()\n",
        "  return dataset\n",
        "\n",
        "# Verifica rótulo gramatical\n",
        "def testtuple(tag):\n",
        "  # verificando todos substantivos.\n",
        "  tags = ['NN','NNS','NNP','NNPS']\n",
        "  for i in tags:\n",
        "    if i == tag:\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "# Filtra palavras da lista gerada pelo pos-tagging \n",
        "# retorna lista de palavras contendo apenas substantivos\n",
        "def filtertuples(tuplelist):\n",
        "  words = []\n",
        "  for tuple in tuplelist:\n",
        "    if testtuple(tuple[1]):\n",
        "      words.append(tuple[0])\n",
        "  return words\n",
        "\n",
        "# remove palavras de menos de 3 letras da lista de palavras e retorna lista\n",
        "def removewords(wordlist):\n",
        "  for word in wordlist:\n",
        "    if len(word) < 3:\n",
        "      wordlist.remove(word)\n",
        "  return wordlist\n",
        "\n",
        "# concatena palavras da lista de palavras numa única string\n",
        "def concatenastring(wordlist):\n",
        "  return ' '.join(wordlist)\n",
        "\n",
        "# Retorna união de dois dataframes (words0 e words1) na coluna 'col' \n",
        "def datamerge(words0,words1,col):\n",
        "  merged = pd.merge(words0,words1, on=[col], how='outer')\n",
        "  merged = dataclean(merged).fillna(0)\n",
        "  return merged.sort_values(by=[col])\n",
        "\n",
        "# Cosseno não ponderado, calculado a partir de frequências simples\n",
        "def cosine_simples(mergedf):\n",
        "  numerador = 0\n",
        "  denominador = 0\n",
        "  vetx = 0\n",
        "  vety = 0\n",
        "  for idx, row in mergedf.iterrows():\n",
        "    numerador += row['freq_x'] * row['freq_y']\n",
        "    vetx += pow(row['freq_x'],2)\n",
        "    vety += pow(row['freq_y'],2)\n",
        "  vetx = math.sqrt(vetx)\n",
        "  vety = math.sqrt(vety)\n",
        "  denominador = vetx * vety\n",
        "  return numerador/denominador\n",
        "\n",
        "# Similaridade com base na média das similaridades máximas entre palavras\n",
        "# recebe duas listas de palavras: wdlist0 -> usermodel; wdlist1 -> filme \n",
        "def similaridade_WP_max(wdlist0,wdlist1):\n",
        "  maximos = []\n",
        "  vals = []\n",
        "  aux = 0\n",
        "  for wd0 in wdlist0:\n",
        "    syn0 = wn.synsets(wd0)\n",
        "    # verifica se 1a palavra contém alguma definição antes de prosseguir\n",
        "    if len(syn0) > 0:\n",
        "      vals.clear()\n",
        "      for wd1 in wdlist1:\n",
        "        syn1 = wn.synsets(wd1)\n",
        "        # verifica se 2a palavra contém alguma definição antes de calcular similaridade\n",
        "        if len(syn1) > 0:\n",
        "          aux = syn0[0].wup_similarity(syn1[0])\n",
        "          # se similaridade = 1, palavras iguais, break\n",
        "          if aux == 1:\n",
        "            break\n",
        "          # senão, adiciona valor à lista vals\n",
        "          else:\n",
        "            vals.append(aux)\n",
        "      # se aux = 1, similaridade máxima = 1\n",
        "      if aux == 1:\n",
        "         maximos.append(aux)\n",
        "      # senão seleciona máxima da lista\n",
        "      else:\n",
        "        maximos.append(max(vals))\n",
        "  if len(maximos) == 0:\n",
        "    return None\n",
        "  else:\n",
        "    return sum(maximos)/len(maximos)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkon-CDeW5bt"
      },
      "outputs": [],
      "source": [
        "# Retorna dataframe de lemmas do wordnet das palavras contidas na lista 'wordlist'\n",
        "def getlemmas(wordlist):\n",
        "  lemmas = []\n",
        "  na = 'N\\A'\n",
        "  for wd in wordlist:\n",
        "    syn = wn.synsets(wd)\n",
        "    if len(syn) > 0:\n",
        "      if len(syn[0].lemmas()) > 0:\n",
        "        lemmas.append(syn[0].lemmas()[0].name())\n",
        "      else:\n",
        "        lemmas.append(na)\n",
        "  return pd.DataFrame(zip(lemmas),columns =['lemma'])\n",
        "\n",
        "# Retorna tabela de frequências dos lemmas\n",
        "def lemmafreqs(df0,df1):\n",
        "  df0 = lemmafreqaux(df0)\n",
        "  df1 = lemmafreqaux(df1)\n",
        "  return datamerge(df0,df1,'lemma')\n",
        "\n",
        "# auxiliar á função lemmafreqs para coletar lemmas válidos\n",
        "# retorna dataframe de lemmas com coluna de frequências\n",
        "def lemmafreqaux(df):\n",
        "  aux = []\n",
        "  # percorre o dataframe de uma coluna\n",
        "  for idx, row in df.iterrows():\n",
        "    if row['lemma'] != 'N\\A':\n",
        "      aux.append(row['lemma'])\n",
        "  return returndataset(aux,'lemma')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qeGsrP5hV1_"
      },
      "outputs": [],
      "source": [
        "# Funções de comparação recebem duas strings e comparam a primeira com a segunda \n",
        "# Comparação de substantivos utilizando cosine simples ou wupalmer\n",
        "def compwords(frase0,frase1,analise):\n",
        "  # converte duas strings para lista de palavras\n",
        "  frase0 = frase0.split()\n",
        "  frase1 = frase1.split()\n",
        "  # Retorna resultado de acordo com parâmetros de análise selecionado\n",
        "  if analise == 'w':\n",
        "    return similaridade_WP_max(frase0,frase1)\n",
        "  elif analise == 'c':\n",
        "    str0 = returndataset(frase0,'word')\n",
        "    str1 = returndataset(frase1,'word')\n",
        "    df = datamerge(str0,str1,'word')\n",
        "    return cosine_simples(df)\n",
        "# Comparação de lemmas utilizando cosine simples\n",
        "def complemmas(frase0,frase1):\n",
        "  # converte duas strings para lista de palavras\n",
        "  frase0 = frase0.split()\n",
        "  frase1 = frase1.split()\n",
        "  # recebe dataframes de lemmas das respectivas frases\n",
        "  str0 = getlemmas(frase0)\n",
        "  str1 = getlemmas(frase1)\n",
        "  df = lemmafreqs(str0,str1)\n",
        "  return cosine_simples(df)\n",
        "# comparação utilizando o cosine do Scikit-learn\n",
        "def compscikit(frase0,frase1):\n",
        "  corpus = [frase0,frase1]\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  trsfm=vectorizer.fit_transform(corpus)\n",
        "  return cosine_similarity(trsfm[0:1], trsfm)[0][1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zw49iuWWb-m",
        "outputId": "7b2a2ddc-48b4-4181-9efa-51265e5bfec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frase0: airbnb listings china years lockdowns country\n",
            "frase1: summer airbnb listings offers experiences china\n",
            "frase2: brands apple lauder impact restrictions\n",
            "\n",
            "######## Média das máximas Wu-Palmer (substantivos) ########\n",
            "strings 0 e 0: 1.0\n",
            "strings 0 e 1: 0.7073015873015873\n",
            "strings 0 e 2: 0.31650793650793646\n",
            "######## Tempo de execução: 0.02430248260498047 ########\n",
            "\n",
            "######## Cosine não ponderado (substantivos) ########\n",
            "strings 0 e 0: 1.0000000000000002\n",
            "strings 0 e 1: 0.5000000000000001\n",
            "strings 0 e 2: 0.0\n",
            "######## Tempo de execução: 0.06583738327026367 ########\n",
            "\n",
            "######## Cosine do Scikit (substantivos) ########\n",
            "strings 0 e 1: 0.33609692727625745\n",
            "strings 0 e 2: 0.0\n",
            "######## Tempo de execução: 0.007732868194580078 ########\n",
            "\n",
            "######## Cosine não ponderado (lemmas do wordnet) ########\n",
            "strings 0 e 0: 0.9999999999999998\n",
            "strings 0 e 1: 0.3999999999999999\n",
            "strings 0 e 2: 0.0\n",
            "######## Tempo de execução: 0.09106564521789551 ########\n"
          ]
        }
      ],
      "source": [
        "# Testes iniciais com frases simples\n",
        "frases = [\"Airbnb will shut down its listings in China after two years of lockdowns in the country.\",\n",
        "        \"Starting this summer, Airbnb will take down its listings and offers for hosted experiences in China.\",\n",
        "        \"International brands, from Apple to Estee Lauder, have warned of the financial impact of the restrictions.\"]\n",
        "# pré-processamento das frases\n",
        "str0 = concatenastring(filtertuples(postagtokenize(frases[0].lower())))\n",
        "str1 = concatenastring(filtertuples(postagtokenize(frases[1].lower())))\n",
        "str2 = concatenastring(filtertuples(postagtokenize(frases[2].lower())))\n",
        "print('frase0: '+str0)\n",
        "print('frase1: '+str1)\n",
        "print('frase2: '+str2)\n",
        "\n",
        "start = tm.time()\n",
        "print(\"\\n######## Média das máximas Wu-Palmer (substantivos) ########\")\n",
        "print(\"strings 0 e 0: \" + str(compwords(str0,str0,'w')))\n",
        "print(\"strings 0 e 1: \" + str(compwords(str0,str1,'w')))\n",
        "print(\"strings 0 e 2: \" + str(compwords(str0,str2,'w')))\n",
        "end = tm.time()\n",
        "print(\"######## Tempo de execução:\", end-start,\"########\")\n",
        "\n",
        "start = tm.time()\n",
        "print(\"\\n######## Cosine não ponderado (substantivos) ########\")\n",
        "print(\"strings 0 e 0: \" + str(compwords(str0,str0,'c')))\n",
        "print(\"strings 0 e 1: \" + str(compwords(str0,str1,'c')))\n",
        "print(\"strings 0 e 2: \" + str(compwords(str0,str2,'c')))\n",
        "end = tm.time()\n",
        "print(\"######## Tempo de execução:\", end-start,\"########\")\n",
        "\n",
        "start = tm.time()\n",
        "print('\\n######## Cosine do Scikit (substantivos) ########')\n",
        "print(\"strings 0 e 1: \" + str(compscikit(str0,str1)))\n",
        "print(\"strings 0 e 2: \" + str(compscikit(str0,str2)))\n",
        "end = tm.time()\n",
        "print(\"######## Tempo de execução:\", end-start,\"########\")\n",
        "\n",
        "start = tm.time()\n",
        "print('\\n######## Cosine não ponderado (lemmas do wordnet) ########')\n",
        "print(\"strings 0 e 0: \" + str(complemmas(str0,str0)))\n",
        "print(\"strings 0 e 1: \" + str(complemmas(str0,str1)))\n",
        "print(\"strings 0 e 2: \" + str(complemmas(str0,str2)))\n",
        "end = tm.time()\n",
        "print(\"######## Tempo de execução:\", end-start,\"########\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPnYyw4MdM1B",
        "outputId": "444b2c89-a724-4d7b-88ee-7c114e55d4ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      movieId                                      title  \\\n",
            "0           1                           Toy Story (1995)   \n",
            "1           2                             Jumanji (1995)   \n",
            "2           3                    Grumpier Old Men (1995)   \n",
            "3           4                   Waiting to Exhale (1995)   \n",
            "4           5         Father of the Bride Part II (1995)   \n",
            "...       ...                                        ...   \n",
            "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
            "9738   193583               No Game No Life: Zero (2017)   \n",
            "9739   193585                               Flint (2017)   \n",
            "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
            "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
            "\n",
            "                                           genres  \\\n",
            "0     Adventure|Animation|Children|Comedy|Fantasy   \n",
            "1                      Adventure|Children|Fantasy   \n",
            "2                                  Comedy|Romance   \n",
            "3                            Comedy|Drama|Romance   \n",
            "4                                          Comedy   \n",
            "...                                           ...   \n",
            "9737              Action|Animation|Comedy|Fantasy   \n",
            "9738                     Animation|Comedy|Fantasy   \n",
            "9739                                        Drama   \n",
            "9740                             Action|Animation   \n",
            "9741                                       Comedy   \n",
            "\n",
            "                                                 string  \n",
            "0      toy story adventure animation children pixar fun  \n",
            "1     jumanji adventure children board game robin wi...  \n",
            "2                     grumpier men comedy romance moldy  \n",
            "3                                  comedy drama romance  \n",
            "4                          father part comedy pregnancy  \n",
            "...                                                 ...  \n",
            "9737  butler book atlantic action animation comedy f...  \n",
            "9738            game life zero animation comedy fantasy  \n",
            "9739                                        flint drama  \n",
            "9740                  bungo dogs apple action animation  \n",
            "9741                             clay dice rules comedy  \n",
            "\n",
            "[9742 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "# carregamento da base de dados de filmes\n",
        "urls = [\"https://raw.githubusercontent.com/GabrielFCosta/preprocessamento/main/movies.csv\",\n",
        "        \"https://raw.githubusercontent.com/GabrielFCosta/preprocessamento/main/ratings.csv\",\n",
        "        \"https://raw.githubusercontent.com/GabrielFCosta/preprocessamento/main/tags.csv\"]\n",
        "datasets = []\n",
        "for url in urls:\n",
        "  df = pd.read_csv(url)\n",
        "  datasets.append(df)\n",
        "# concatena títulos e gêneros, substituindo barras verticais por espaços na coluna de genêros,\n",
        "# ...na nova coluna 'string' da base de filmes\n",
        "datasets[0]['string'] = datasets[0]['title'] + datasets[0]['genres'].str.replace('|', ' ', regex=True)\n",
        "auxlist =[]\n",
        "# concatenando tags de usuários\n",
        "for idx1, row in datasets[0].iterrows():\n",
        "  # para cada filme filtra as tags do filme num dataframe \n",
        "  usertags = datasets[2].loc[datasets[2]['movieId'] == row['movieId'] ] \n",
        "  aux =''\n",
        "  # percorre dataframe de tags concatenando tags numa string 'aux'\n",
        "  for idx2, tags in usertags.iterrows():\n",
        "    aux = aux + tags['tag'] + ' '\n",
        "  # coloca string 'aux' numa lista 'auxlist'\n",
        "  auxlist.append(aux)\n",
        "# concatena string de tags à coluna de string no banco\n",
        "datasets[0]['string'] = datasets[0]['string'] + ' ' + auxlist\n",
        "auxlist.clear()\n",
        "# pré-processamento prévio da string, para cada string da coluna 'string'\n",
        "auxl = []\n",
        "for idx, row in datasets[0].iterrows():\n",
        "  # faz o POS tagging, remove uppercases e seleciona todos substantivos\n",
        "  auxl = filtertuples(postagtokenize(row['string'].lower()))\n",
        "  # remove substantivos duplicados\n",
        "  auxl = list(dict.fromkeys(auxl))\n",
        "  # remove substantivos com menos de 3 letras, converte lista pra string\n",
        "  auxl = concatenastring(removewords(auxl))\n",
        "  auxlist.append(auxl)\n",
        "datasets[0]['string'] = auxlist\n",
        "auxlist.clear()\n",
        "print(datasets[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-_wgIhHMee5",
        "outputId": "f719e497-3a69-4b4b-988f-9b1b3eea5062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#### TESTE 1 ####\n",
            "userId: 42\n",
            "filmes assistidos: 440\n",
            "filmes filtrados: 9302\n",
            "movieId: 2989\n",
            "string: eyes action adventure thriller\n",
            "PosTags com média de máximas WuPalmer: 0.6\n",
            "    movieId  max_rated  postag_wp\n",
            "5      1722          1   0.857143\n",
            "4      1210          1   0.805556\n",
            "3      1517          1   0.695378\n",
            "10     5953          0   0.660189\n",
            "14     3629          0   0.626471\n",
            "9       253          1   0.601554\n",
            "12     6998          0   0.595851\n",
            "0        16          1   0.568627\n",
            "17     1804          0   0.568627\n",
            "2      2371          1   0.509804\n",
            "PosTags com Cosine: 0.3\n",
            "    movieId  max_rated  postag_cos\n",
            "5      1722          1    0.750000\n",
            "3      1517          1    0.408248\n",
            "4      1210          1    0.277350\n",
            "19   174479          0    0.250000\n",
            "16       45          0    0.250000\n",
            "14     3629          0    0.204124\n",
            "18    48262          0    0.000000\n",
            "12     6998          0    0.000000\n",
            "10     5953          0    0.000000\n",
            "15     5840          0    0.000000\n",
            "Lemmas do Wordnet com Cosine: 0.3\n",
            "    movieId  max_rated  wnet_lemma_cos\n",
            "5      1722          1        0.750000\n",
            "3      1517          1        0.408248\n",
            "4      1210          1        0.333333\n",
            "19   174479          0        0.250000\n",
            "16       45          0        0.250000\n",
            "14     3629          0        0.204124\n",
            "18    48262          0        0.000000\n",
            "12     6998          0        0.000000\n",
            "10     5953          0        0.000000\n",
            "15     5840          0        0.000000\n",
            "precisão do Scikit: 0.3\n",
            "0 : 1.0\n",
            "1 : 2.0\n",
            "2 : 3.0\n",
            "3 : 3.75\n",
            "4 : 4.35\n",
            "5 : 4.85\n",
            "6 : 5.2785714285714285\n",
            "7 : 5.6535714285714285\n",
            "8 : 5.9869047619047615\n",
            "9 : 6.286904761904761\n",
            "mrr do Scikit: 0.6286904761904761\n",
            "    movieId  max_rated  scikit_cos\n",
            "5      1722          1    0.602975\n",
            "3      1517          1    0.260556\n",
            "4      1210          1    0.168310\n",
            "19   174479          0    0.144384\n",
            "16       45          0    0.144384\n",
            "14     3629          0    0.115216\n",
            "18    48262          0    0.000000\n",
            "12     6998          0    0.000000\n",
            "10     5953          0    0.000000\n",
            "15     5840          0    0.000000\n"
          ]
        }
      ],
      "source": [
        "# recebe o dataframe de onde serão sorteados (df); quantidade a ser sorteada (qtd);\n",
        "# rótulo que deve ser adicionado, 0 ou 1, (maxrated); semente para sorteio reproduzivel (state)\n",
        "# retorna dataframe de amostras de filmes pseudo-aleatórios com rótulos de rating\n",
        "def sampledata(df,qtd,maxrated,state):\n",
        "  data = pd.DataFrame()\n",
        "  data = df.sample(n = qtd, random_state = state)\n",
        "  data = data.astype({'movieId':'int'})\n",
        "  data[\"max_rated\"] = maxrated\n",
        "  return data\n",
        "\n",
        "# junta dois dataframes de movieIds e rótulos de classe\n",
        "# retorna dataframe contendo movieIds e rótulos, ordenado por movieId\n",
        "def mergesamples(usersample,mids):\n",
        "  merged = pd.merge(usersample,mids, on=['movieId'], how='outer')\n",
        "  merged = dataclean(merged).fillna(0)\n",
        "  merged = merged.astype({'max_rated_x':'int'})\n",
        "  merged.rename(columns = {'max_rated_x':'max_rated'}, inplace = True)\n",
        "  merged.drop(['userId', 'rating', 'max_rated_y'], axis=1, inplace=True)\n",
        "  return merged.sort_values(by=['movieId'])\n",
        "\n",
        "# Retorna string do filme a partir do movieId\n",
        "def returnstring(movieId):\n",
        "  ref = datasets[0][datasets[0]['movieId'] == movieId]\n",
        "  return ref['string'].iloc[0]\n",
        "\n",
        "# Comparação seletiva. recebe string do usuário (usermodel),\n",
        "# Dataframe dos dados de teste (testsample) e indicador da análise\n",
        "# retorna dataframe contendo 10 resultados do topo da análise\n",
        "def batchcompare(usermodel,testsample,analise):\n",
        "  samplelist = []\n",
        "  valores = []\n",
        "  df  = pd.DataFrame()\n",
        "  df = testsample.copy(deep=True)\n",
        "  # coleta todas as strings dos filmes de teste na lista samplelist\n",
        "  for idx, row in testsample.iterrows():\n",
        "    samplelist.append(returnstring(row['movieId']))\n",
        "  # compara de acordo com o parâmetro comparison\n",
        "  if analise == 'max_wp':\n",
        "    for frase in samplelist:\n",
        "      valores.append(compwords(usermodel,frase,'w'))\n",
        "    df[analise] = valores\n",
        "    return df.sort_values(by=[analise], ascending = False).head(10)\n",
        "  elif analise == 'cos_ns':\n",
        "    for frase in samplelist:\n",
        "      valores.append(compwords(usermodel,frase,'c'))\n",
        "    df[analise] = valores\n",
        "    return df.sort_values(by=[analise], ascending = False).head(10)\n",
        "  elif analise == 'cos_ls':\n",
        "    for frase in samplelist:\n",
        "      valores.append(complemmas(usermodel,frase))\n",
        "    df[analise] = valores\n",
        "    return df.sort_values(by=[analise], ascending = False).head(10)\n",
        "  elif analise == 'cos_sk':\n",
        "    for frase in samplelist:\n",
        "      valores.append(compscikit(usermodel,frase))\n",
        "    df[analise] = valores\n",
        "    return df.sort_values(by=[analise], ascending = False).head(10)\n",
        "  return None\n",
        "\n",
        "def calculaprecisao(lista,kpos):\n",
        "  c = 0\n",
        "  for i in lista[0:kpos]:\n",
        "    if i == 1:\n",
        "      c+=1\n",
        "  return c/kpos\n",
        "\n",
        "def calculamrr(lista,kpos):\n",
        "  c = 0\n",
        "  for i in range(kpos):\n",
        "    c += calculaprecisao(lista,i+1)\n",
        "    print(str(i) + \" : \" + str(c) )\n",
        "  return c/kpos\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2o. Análise em lotes\n",
        "def analyse(times):\n",
        "  random.seed(0)\n",
        "  for i in range(times):\n",
        "    print(\"\\n#### TESTE \"+str(i+1)+\" ####\")\n",
        "    # usuário deve ter mais de 10 filmes com avaliação 5\n",
        "    user =  pd.DataFrame()\n",
        "    while user.shape[0] < 11:\n",
        "      # sorteia usuário\n",
        "      id = random.randrange(1, 610)\n",
        "      # filtra todos os filmes de avaliação máxima do usuário sorteado\n",
        "      user = datasets[1].loc[(datasets[1]['userId'] == id) & (datasets[1]['rating'] == 5.0)]\n",
        "    print(\"userId: \"+str(id))\n",
        "    # sorteia 11 filmes de avaliação máxima do usuário\n",
        "    usersample = pd.DataFrame()\n",
        "    usersample = sampledata(user,11,1)\n",
        "    #print(usersample)\n",
        "    # pega todos os ids de filmes da base original\n",
        "    mids = pd.DataFrame()\n",
        "    mids['movieId'] = datasets[0]['movieId']\n",
        "    #print(\"total de filmes: \"+str(mids.shape[0]))\n",
        "    # pega todos os filmes do usuário\n",
        "    watched = pd.DataFrame()\n",
        "    watched = datasets[1].loc[(datasets[1]['userId'] == id)]\n",
        "    print(\"filmes assistidos: \"+str(watched.shape[0]))\n",
        "    # primeiro exclui todos filmes do usuário do total de filmes...\n",
        "    mask = mids['movieId'].isin(watched['movieId'].tolist())\n",
        "    mids = mids[~mask]\n",
        "    print(\"filmes filtrados: \"+str(mids.shape[0]))\n",
        "    # ...depois sorteia 10 outros filmes não assistidos dos que restaram\n",
        "    mids = sampledata(mids,10,0)\n",
        "    # dos 11 do usuário, sorteia 1 para servir de referência e o exclui do resto\n",
        "    reference =  pd.DataFrame()\n",
        "    reference = usersample.sample(random_state = 0)\n",
        "    usermodel = reference['movieId'].iloc[0]\n",
        "    index = usersample[usersample['movieId'] == usermodel].index\n",
        "    usersample = usersample.drop(index)\n",
        "    print('movieId: '+str(usermodel))\n",
        "    usermodel = returnstring(usermodel)\n",
        "    print('string: '+usermodel)\n",
        "    \n",
        "    # dados de teste rotulados. 10 filmes de rating máximo mais 10 não assistidos\n",
        "    testsample = mergesamples(usersample,mids)\n",
        "    df = pd.DataFrame()\n",
        "    # tenta as análises sequencialmente\n",
        "    try:\n",
        "      df = batchcompare(usermodel,testsample,'posw') \n",
        "      print(\"PosTags com média de máximas WuPalmer: \" + str(calculaprecisao(df['max_rated'].tolist(),10)))\n",
        "      print(df)\n",
        "    except:\n",
        "      print(\"PosTags com média de máximas WuPalmer não funcionou.\")\n",
        "    try:\n",
        "      df = batchcompare(usermodel,testsample,'posc')\n",
        "      print(\"PosTags com Cosine: \" + str(calculaprecisao(df['max_rated'].tolist(),10)))\n",
        "      print(df)\n",
        "    except:\n",
        "      print(\"PosTags com Cosine não funcionou.\")\n",
        "    try:\n",
        "      df = batchcompare(usermodel,testsample,'wnet')\n",
        "      print(\"Lemmas do Wordnet com Cosine: \" + str(calculaprecisao(df['max_rated'].tolist(),10)))\n",
        "      print(df)\n",
        "    except:\n",
        "      print(\"Lemmas do Wordnet com Cosine não funcionou.\")\n",
        "    try:\n",
        "      df = batchcompare(usermodel,testsample,'scik')\n",
        "      print(\"precisão do Scikit: \" + str(calculaprecisao(df['max_rated'].tolist(),10)))\n",
        "      print(\"mrr do Scikit: \" + str(calculamrr(df['max_rated'].tolist(),10)))\n",
        "      print(df)\n",
        "    except:\n",
        "      print(\"Cosine do Scikit não funcionou.\")\n",
        "\n",
        "\n",
        "analyse(1)\n",
        "\n",
        "#datasets[0].loc[datasets[0]['movieId'] == 1031]\n",
        "#datasets[1].loc[datasets[1]['userId'] == 143]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSY9zYBjJGxm",
        "outputId": "87c48d88-62b2-4c67-fe87-f46b206fae6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#### TESTE 1 ####\n",
            "userId: 374\n",
            "['braveheart', 'action', 'drama', 'war', 'scenery', 'medieval', 'mel', 'gibson', 'oscar', 'cinematography', 'revenge', 'sword', 'fight', 'scotland']\n",
            "['batman', 'forever', 'action', 'adventure', 'comedy', 'crime', 'superhero']\n",
            "['crimson', 'tide', 'drama', 'thriller', 'war', 'submarine']\n",
            "['dumb', 'dumber', 'adventure', 'comedy']\n",
            "['pulp', 'fiction', 'comedy', 'crime', 'drama', 'thriller', 'dialogue', 'cult', 'film', 'drugs', 'tarantino', 'men', 'action', 'amazing', 'dialogues', 'awesome', 'ass', 'language', 'bad-ass', 'references', 'boys', 'guns', 'name', 'actors', 'humor', 'humour', 'blood', 'splatters', 'brutality', 'violence', 'character', 'development', 'characters', 'movie', 'coke', 'conversation', 'style', 'scene', 'dance', 'diner', 'drug', 'music', 'cast', 'fun', 'gangster', 'gangsters', 'watch', 'gore', 'soundtrack', 'keitel', 'heroin', 'hit', 'homosexuality', 'imdb', 'intelligent', 'storylines', 'irony', 'john', 'los', 'angeles', 'masterpiece', 'meaningless', 'milkshake', 'mobster', 'mobsters', 'motherfucker', 'multiple', 'stories', 'timeline', 'storyline', 'offensive', 'plot', 'order', 'palme', \"d'or\", 'parody', 'pop', 'culture', 'quentin', 'quirky', 'violent', 'content', 'rape', 'images', 'sexuality', 'bloody', 'random', 'retro', 'roger', 'royal', 'samuel', 'jackson', 'sarcasm', 'satire', 'writing', 'splatter', 'buscemi', 'suspense', 'travolta', 'twist', 'thurman', 'unique', 'witty']\n",
            "['redemption', 'crime', 'drama', 'prison', 'imprisonment', 'morgan', 'freeman']\n",
            "['ace', 'ventura', 'detective', 'comedy']\n",
            "['gump', 'comedy', 'drama', 'romance', 'war', 'shrimp', 'bubba', 'dan', 'stupid', 'heartwarming']\n",
            "['lies', 'action', 'adventure', 'comedy', 'romance', 'thriller', 'spies']\n",
            "['park', 'action', 'adventure', 'thriller', 'dinosaur']\n",
            "['independence', 'day', 'a.k.a', 'id4', 'action', 'adventure', 'thriller', 'aliens']\n",
            "['army', 'darkness', 'action', 'adventure', 'comedy', 'fantasy', 'horror']\n",
            "['shining', 'horror', 'jack', 'stanley', 'kubrick', 'suspense', 'stephen']\n",
            "['birds', 'horror', 'thriller']\n",
            "['carrie', 'drama', 'horror', 'thriller', 'school', 'stephen', 'king']\n",
            "['omen', 'horror', 'mystery', 'thriller', 'demons']\n",
            "['star', 'trek', 'contact', 'action', 'adventure', 'thriller', 'borg']\n",
            "          word  freq\n",
            "24    thriller     9\n",
            "1       action     8\n",
            "17   adventure     7\n",
            "18      comedy     7\n",
            "2        drama     6\n",
            "181     horror     5\n",
            "3          war     3\n",
            "19       crime     3\n",
            "148    romance     2\n",
            "128   suspense     2\n",
            "188    stephen     2\n",
            "121     samuel     1\n",
            "122    jackson     1\n",
            "120      royal     1\n",
            "123    sarcasm     1\n",
            "usermodel: thriller action adventure comedy drama horror war crime romance suspense stephen samuel jackson royal sarcasm\n",
            "filmes assistidos: 33\n",
            "filmes filtrados: 9709\n",
            "PosTags com média de máximas WuPalmer: 0.3\n",
            "    movieId  max_rated  postag_wp\n",
            "3       380          1   0.707879\n",
            "1       356          1   0.692298\n",
            "10    60471          0   0.687543\n",
            "69     1197          0   0.671196\n",
            "6       780          1   0.653849\n",
            "61    31696          0   0.651738\n",
            "71      168          0   0.649667\n",
            "33    32456          0   0.648618\n",
            "25     1210          0   0.646512\n",
            "52   160569          0   0.626589\n",
            "PosTags com Cosine: 0.3\n",
            "    movieId  max_rated  postag_cos\n",
            "3       380          1    0.487950\n",
            "66     2344          0    0.461880\n",
            "10    60471          0    0.461880\n",
            "54     2881          0    0.461880\n",
            "4       153          1    0.390360\n",
            "2      1345          1    0.390360\n",
            "68     1236          0    0.387298\n",
            "81   114925          0    0.387298\n",
            "18   115828          0    0.387298\n",
            "61    31696          0    0.387298\n",
            "Lemmas do Wordnet com Cosine: 0.4\n",
            "    movieId  max_rated  wnet_lemma_cos\n",
            "3       380          1        0.487950\n",
            "66     2344          0        0.461880\n",
            "54     2881          0        0.461880\n",
            "10    60471          0        0.461880\n",
            "4       153          1        0.421637\n",
            "2      1345          1        0.421637\n",
            "69     1197          0        0.390360\n",
            "1       356          1        0.390360\n",
            "71      168          0        0.387298\n",
            "89    47725          0        0.387298\n",
            "Cosine do Scikit: 0.1\n",
            "    movieId  max_rated  scikit_cos\n",
            "3       380          1    0.335912\n",
            "54     2881          0    0.322605\n",
            "66     2344          0    0.322605\n",
            "10    60471          0    0.322605\n",
            "12    70994          0    0.268805\n",
            "18   115828          0    0.260269\n",
            "68     1236          0    0.260269\n",
            "81   114925          0    0.260269\n",
            "51     1327          0    0.260269\n",
            "61    31696          0    0.260269\n"
          ]
        }
      ],
      "source": [
        "\n",
        "'''\n",
        "filmes assistidos = 100\n",
        "filmes assistidos >= 4 = 30\n",
        "filmes para candidate set = 10 de 30\n",
        "filmes do candidate set = 10 + 90 aleatorios não assistidos\n",
        "tags do perfil = 10 ou 15 palavras mais frequentes dos 30\n",
        "calcula precisão @ 3, 5, 10\n",
        "calcula mrr @ posição 3, 5, 10 (qtd relevantes / posição)\n",
        "calcula map (média da precisão de vários usuário, pra 3, 5, 10)\n",
        "'''\n",
        "\n",
        "# retorna string dos termos mais frequentes do perfil de usuário\n",
        "def returnperfil(wordlist):\n",
        "  # junta lista de palavras e rótulo num dataframe\n",
        "  dataset = pd.DataFrame(wordlist,columns =['word'])\n",
        "  # calcula frequências das palavras e adiciona nova coluna\n",
        "  dataset['freq'] = dataset.groupby(['word'])['word'].transform('count')\n",
        "  dataset = dataclean(dataset)\n",
        "  # ordena palavras de acordo com frequência\n",
        "  dataset = dataset.sort_values(by=['freq'], ascending = False).head(15)\n",
        "  return concatenastring(dataset['word'].tolist())\n",
        "\n",
        "# recebe dataframe dos filmes bem avaliados pelo usuário\n",
        "# retorna string do perfil do usuário\n",
        "def perfilusuario(user):\n",
        "  userstring = []\n",
        "  wordlist = []\n",
        "  for idx, row in user.iterrows():\n",
        "    # converte strings dos filmes do usuário em listas\n",
        "    userstring = returnstring(row['movieId']).split()\n",
        "    # junta tudo numa única lista\n",
        "    for word in userstring:\n",
        "      wordlist.append(word)\n",
        "  return returnperfil(wordlist)\n",
        "\n",
        "# recebe dataframe do usuário e id do usuário para semente aleatória\n",
        "# retorna dataframe vazio se no. de filmes não avaliados pelo usuário < 90\n",
        "def sorteiadados(userdf,userid):\n",
        "  # sorteia 10 filmes do usuário para os dados de teste\n",
        "  usersample = pd.DataFrame()\n",
        "  usersample = sampledata(userdf,10,1,userid)\n",
        "  # pega todos os ids de filmes da base original\n",
        "  mids = pd.DataFrame()\n",
        "  mids['movieId'] = datasets[0]['movieId']\n",
        "  # pega todos os filmes do usuário\n",
        "  watched = pd.DataFrame()\n",
        "  watched = datasets[1].loc[(datasets[1]['userId'] == userid)]\n",
        "  # exclui todos filmes do usuário do total de filmes\n",
        "  mask = mids['movieId'].isin(watched['movieId'].tolist())\n",
        "  mids = mids[~mask]\n",
        "  # filmes não avaliados devem totalizar pelo menos 90\n",
        "  if mids.shape[0] == 90:\n",
        "    return mergesamples(usersample,mids)\n",
        "  elif mids.shape[0] > 90:\n",
        "    # sorteia 90 outros filmes não avaliados\n",
        "    mids = sampledata(mids,90,0,userid)\n",
        "    # dados de teste rotulados. 10 filmes de rating 1 mais 90 de 0\n",
        "    return mergesamples(usersample,mids)\n",
        "  return pd.DataFrame()\n",
        "\n",
        "# tenta uma análise individualmente e retorna lista de resultados\n",
        "def getresults(usermodel,testsample,analise):\n",
        "  results = []\n",
        "  df = pd.DataFrame()\n",
        "  try:\n",
        "    df = batchcompare(usermodel,testsample,analise) \n",
        "    results.append(calculaprecisao(df['max_rated'].tolist(),3))\n",
        "    results.append(calculaprecisao(df['max_rated'].tolist(),5))\n",
        "    results.append(calculaprecisao(df['max_rated'].tolist(),10))\n",
        "    results.append(calculamrr(df['max_rated'].tolist(),3))\n",
        "    results.append(calculamrr(df['max_rated'].tolist(),5))\n",
        "    results.append(calculamrr(df['max_rated'].tolist(),10))\n",
        "    return results\n",
        "  except:\n",
        "    results.clear()\n",
        "    for i in range(6):\n",
        "      results.append('N\\A')\n",
        "    return results\n",
        "\n",
        "# tenta análises sequencialmente e retorna dataframe de uma linha com resultados\n",
        "def analises(usermodel,testsample,userid):\n",
        "  resultados = pd.DataFrame()\n",
        "  results = [userid]\n",
        "  # concatenando resultados numa única lista\n",
        "  results = getresults(usermodel,testsample,'max_wp')\n",
        "  results = results + getresults(usermodel,testsample,'cos_ns')\n",
        "  results = results + getresults(usermodel,testsample,'cos_ls')\n",
        "  results = results + getresults(usermodel,testsample,'cos_sk')\n",
        "  resultados.loc[0] = results\n",
        "  return resultados\n",
        "\n",
        "# Análise em lotes com base no perfil do usuário\n",
        "def analiseperfil(times):\n",
        "  if times >= 1 and times <= 610:\n",
        "    colunas = ['userId','max_wp_p3','max_wp_p5','max_wp_p10','max_wp_mrr3','max_wp_mrr5','max_wp_mrr10',\n",
        "             'cos_ns_p3','cos_ns_p5','cos_ns_p10','cos_ns_mrr3','cos_ns_mrr5','cos_ns_mrr10',\n",
        "             'cos_ls_p3','cos_ls_p5','cos_ls_p10','cos_ls_mrr3','cos_ls_mrr5','cos_ls_mrr10',\n",
        "             'cos_sk_p3','cos_sk_p5','cos_sk_p10','cos_sk_mrr3','cos_sk_mrr5','cos_sk_mrr10']\n",
        "    resultados = pd.DataFrame(columns=colunas)\n",
        "    # faz a analise para todos os usuários sequencialmente do 1 ao 610\n",
        "    for i in range(times):\n",
        "      id  = i+1\n",
        "      # seleciona todos os filmes do usuário com avaliação > 4\n",
        "      user = datasets[1].loc[(datasets[1]['userId'] == id) & (datasets[1]['rating'] >= 4.0)]\n",
        "      # usuário deve ter mais de 10 filmes com avaliação > 4\n",
        "      if user.shape[0] > 10:\n",
        "        # string do perfil do usuário\n",
        "        usermodel = perfilusuario(user)\n",
        "        # dados de teste devem ter 100 filmes\n",
        "        testsample = sorteiadados(user,id)\n",
        "        if testsample.shape[0] == 100:\n",
        "          df = analises(usermodel,testsample,id)\n",
        "          resultados = pd.concat(resultados,df)\n",
        "\n",
        "\n",
        "    \n",
        "   \n",
        "\n",
        "analiseperfil(1)\n",
        "\n",
        "# datasets[0].to_csv('movies.csv', sep=',', encoding='utf-8')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCDssy+ajOI/Utvsr+BJaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}